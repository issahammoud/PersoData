{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<img src=\"logo.jpg\", width=150, ALIGN=\"left\", border=20>\n",
    "<center>\n",
    "<h1>Sample Starting Kit </h1>\n",
    " <br>This code was tested with <br>\n",
    "Python 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) (https://anaconda.org/)<br>\n",
    "<i> Adapted for Chalab by Isabelle Guyon from original code of Balázs Kégl</i> <br>\n",
    "<a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science (CDS)</a>\n",
    "</center>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<p>\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CDS, CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL, \n",
    "INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Introduction </h2>\n",
    "    <p>\n",
    "In an era where computer graphics techniques for image generation are reaching stunning levels of quality, it becomes more and more challenging to detect fake from true, authentic images. However, this raises a lot of legal issues, mainly dealing with forgery. This project focuses mainly on the efficiency of Generative Adversarial Network (GAN) algorithms for producing art forgery and we will try to beat the state-of-the-art models that detect it. In fact, the Fine Arts Expert Institute in Geneva estimates that as much as 50 percent of artworks currently in circulation may be forgeries. Although the standard approach for image classification which is deep neural networks and especially Convolutional Neural Networks (CNNs) works very well nowadays, GAN performs strongly on generating fake images. By focusing on the art forgery aspect, we will try to bring a more specific perspective on the issue of image forgery.\n",
    " \n",
    " <br>\n",
    "    <span style=\"color:red\"> Keep the next block. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'sample_code_submission/'                        # Change the model to a better one once you have one!\n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir); \n",
    "%matplotlib inline\n",
    "# Uncomment the next lines to auto-reload libraries (this causes some problem with pickles in Python 3)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h1> Step 1: Exploratory data analysis </h1>\n",
    "<p>\n",
    "We provide sample_data with the starting kit, but to prepare your submission, you must fetch the public_data from the challenge website and point to it.\n",
    "    <br>\n",
    "    <span style=\"color:red\"> Just change the data name in the block below. In the rest of the section, replace the sample plots by anything you want. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perso_feat.name    perso_test.data\tperso_train.solution\r\n",
      "perso_label.name   perso_test.solution\tperso_valid.data\r\n",
      "perso_public.info  perso_train.data\tperso_valid.solution\r\n"
     ]
    }
   ],
   "source": [
    "#data_dir = 'sample_data'              # Change this to the directory where you put the input data\n",
    "data_dir = 'sample_data'          # The sample_data directory should contain only a very small subset of the data\n",
    "data_name = 'perso'\n",
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample_data/perso_train from AutoML format\n",
      "Number of examples = 50\n",
      "Number of features = 1024\n",
      "  Class\n",
      "0  faux\n",
      "1  vrai\n",
      "Number of classes = 2\n"
     ]
    }
   ],
   "source": [
    "from data_io import read_as_df\n",
    "data = read_as_df(data_dir  + '/' + data_name)          # The perso_data is loaded as a Pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature1015</th>\n",
       "      <th>feature1016</th>\n",
       "      <th>feature1017</th>\n",
       "      <th>feature1018</th>\n",
       "      <th>feature1019</th>\n",
       "      <th>feature1020</th>\n",
       "      <th>feature1021</th>\n",
       "      <th>feature1022</th>\n",
       "      <th>feature1023</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.229936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113569</td>\n",
       "      <td>0.060445</td>\n",
       "      <td>0.118252</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>1.255350</td>\n",
       "      <td>0.097148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.844707</td>\n",
       "      <td>1.634048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.647042</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>1.041219</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>1.050223</td>\n",
       "      <td>vrai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.383036</td>\n",
       "      <td>1.887521</td>\n",
       "      <td>3.754520</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.895784</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.430044</td>\n",
       "      <td>0.318986</td>\n",
       "      <td>0.461066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084426</td>\n",
       "      <td>2.899674</td>\n",
       "      <td>0.049379</td>\n",
       "      <td>1.090316</td>\n",
       "      <td>0.603634</td>\n",
       "      <td>0.605868</td>\n",
       "      <td>1.864173</td>\n",
       "      <td>vrai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.214969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.687800</td>\n",
       "      <td>1.123374</td>\n",
       "      <td>0.885945</td>\n",
       "      <td>0.462779</td>\n",
       "      <td>0.410846</td>\n",
       "      <td>0.657776</td>\n",
       "      <td>0.212810</td>\n",
       "      <td>0.275802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632619</td>\n",
       "      <td>2.273881</td>\n",
       "      <td>0.894132</td>\n",
       "      <td>0.204060</td>\n",
       "      <td>1.904384</td>\n",
       "      <td>0.157933</td>\n",
       "      <td>1.817468</td>\n",
       "      <td>1.364134</td>\n",
       "      <td>1.502101</td>\n",
       "      <td>vrai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076420</td>\n",
       "      <td>0.383384</td>\n",
       "      <td>0.877510</td>\n",
       "      <td>0.155497</td>\n",
       "      <td>2.587093</td>\n",
       "      <td>0.184072</td>\n",
       "      <td>0.027228</td>\n",
       "      <td>0.282427</td>\n",
       "      <td>0.084898</td>\n",
       "      <td>1.142331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.837352</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.672739</td>\n",
       "      <td>1.137931</td>\n",
       "      <td>0.574607</td>\n",
       "      <td>0.263653</td>\n",
       "      <td>1.672676</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>vrai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.190229</td>\n",
       "      <td>1.315484</td>\n",
       "      <td>0.089153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504714</td>\n",
       "      <td>1.573390</td>\n",
       "      <td>0.785659</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.479984</td>\n",
       "      <td>...</td>\n",
       "      <td>1.754930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036095</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>0.423083</td>\n",
       "      <td>0.392361</td>\n",
       "      <td>0.788016</td>\n",
       "      <td>0.038467</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>vrai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0  0.000000  1.229936  0.000000  0.113569  0.060445  0.118252  0.903643   \n",
       "1  0.000000  1.383036  1.887521  3.754520  0.030029  0.895784  0.038473   \n",
       "2  1.214969  0.000000  1.687800  1.123374  0.885945  0.462779  0.410846   \n",
       "3  0.076420  0.383384  0.877510  0.155497  2.587093  0.184072  0.027228   \n",
       "4  0.000000  1.190229  1.315484  0.089153  0.000000  0.504714  1.573390   \n",
       "\n",
       "   feature7  feature8  feature9   ...    feature1015  feature1016  \\\n",
       "0  0.035282  1.255350  0.097148   ...       1.844707     1.634048   \n",
       "1  0.430044  0.318986  0.461066   ...       0.864230     0.000000   \n",
       "2  0.657776  0.212810  0.275802   ...       0.632619     2.273881   \n",
       "3  0.282427  0.084898  1.142331   ...       1.837352     0.026450   \n",
       "4  0.785659  0.693891  0.479984   ...       1.754930     0.000000   \n",
       "\n",
       "   feature1017  feature1018  feature1019  feature1020  feature1021  \\\n",
       "0     0.000000     0.000662     0.647042     0.084682     1.041219   \n",
       "1     0.084426     2.899674     0.049379     1.090316     0.603634   \n",
       "2     0.894132     0.204060     1.904384     0.157933     1.817468   \n",
       "3     0.000000     1.672739     1.137931     0.574607     0.263653   \n",
       "4     0.036095     0.022705     0.423083     0.392361     0.788016   \n",
       "\n",
       "   feature1022  feature1023  target  \n",
       "0     0.075019     1.050223    vrai  \n",
       "1     0.605868     1.864173    vrai  \n",
       "2     1.364134     1.502101    vrai  \n",
       "3     1.672676     0.009960    vrai  \n",
       "4     0.038467     0.040568    vrai  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we load the data as a \"pandas\" data frame, so we can use \"pandas\" and \"seaborn\" built in functions to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature1014</th>\n",
       "      <th>feature1015</th>\n",
       "      <th>feature1016</th>\n",
       "      <th>feature1017</th>\n",
       "      <th>feature1018</th>\n",
       "      <th>feature1019</th>\n",
       "      <th>feature1020</th>\n",
       "      <th>feature1021</th>\n",
       "      <th>feature1022</th>\n",
       "      <th>feature1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.356115</td>\n",
       "      <td>0.659151</td>\n",
       "      <td>0.534851</td>\n",
       "      <td>1.456609</td>\n",
       "      <td>0.620374</td>\n",
       "      <td>0.246584</td>\n",
       "      <td>0.492389</td>\n",
       "      <td>0.561619</td>\n",
       "      <td>0.351571</td>\n",
       "      <td>0.326255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348105</td>\n",
       "      <td>0.516225</td>\n",
       "      <td>0.331030</td>\n",
       "      <td>0.426340</td>\n",
       "      <td>0.901045</td>\n",
       "      <td>0.854171</td>\n",
       "      <td>2.114770</td>\n",
       "      <td>0.898444</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.524872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.528450</td>\n",
       "      <td>0.717040</td>\n",
       "      <td>0.634626</td>\n",
       "      <td>1.469262</td>\n",
       "      <td>0.863010</td>\n",
       "      <td>0.516834</td>\n",
       "      <td>0.615499</td>\n",
       "      <td>0.786240</td>\n",
       "      <td>0.504510</td>\n",
       "      <td>0.529641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596924</td>\n",
       "      <td>0.714570</td>\n",
       "      <td>0.593420</td>\n",
       "      <td>0.541888</td>\n",
       "      <td>1.082123</td>\n",
       "      <td>0.938720</td>\n",
       "      <td>2.271520</td>\n",
       "      <td>0.881170</td>\n",
       "      <td>1.180123</td>\n",
       "      <td>0.543327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041860</td>\n",
       "      <td>0.142003</td>\n",
       "      <td>0.049615</td>\n",
       "      <td>0.287843</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.127216</td>\n",
       "      <td>0.490579</td>\n",
       "      <td>0.207641</td>\n",
       "      <td>1.129262</td>\n",
       "      <td>0.065244</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.160384</td>\n",
       "      <td>0.235029</td>\n",
       "      <td>0.126061</td>\n",
       "      <td>0.087056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>0.147620</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.295788</td>\n",
       "      <td>0.338905</td>\n",
       "      <td>0.495983</td>\n",
       "      <td>0.958504</td>\n",
       "      <td>0.722759</td>\n",
       "      <td>0.229320</td>\n",
       "      <td>0.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.588773</td>\n",
       "      <td>0.997432</td>\n",
       "      <td>0.863077</td>\n",
       "      <td>2.156846</td>\n",
       "      <td>1.134359</td>\n",
       "      <td>0.231311</td>\n",
       "      <td>0.774815</td>\n",
       "      <td>0.796812</td>\n",
       "      <td>0.432390</td>\n",
       "      <td>0.494191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457193</td>\n",
       "      <td>0.890692</td>\n",
       "      <td>0.446506</td>\n",
       "      <td>0.636890</td>\n",
       "      <td>1.380113</td>\n",
       "      <td>1.505200</td>\n",
       "      <td>5.172260</td>\n",
       "      <td>1.607077</td>\n",
       "      <td>1.638849</td>\n",
       "      <td>0.772724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.387135</td>\n",
       "      <td>2.503587</td>\n",
       "      <td>2.039248</td>\n",
       "      <td>5.101050</td>\n",
       "      <td>3.332864</td>\n",
       "      <td>2.486209</td>\n",
       "      <td>2.051370</td>\n",
       "      <td>3.632538</td>\n",
       "      <td>1.927134</td>\n",
       "      <td>2.294356</td>\n",
       "      <td>...</td>\n",
       "      <td>2.975513</td>\n",
       "      <td>3.255536</td>\n",
       "      <td>2.505214</td>\n",
       "      <td>2.708307</td>\n",
       "      <td>4.099638</td>\n",
       "      <td>2.904099</td>\n",
       "      <td>5.694676</td>\n",
       "      <td>3.223482</td>\n",
       "      <td>4.226102</td>\n",
       "      <td>1.864173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature0   feature1   feature2   feature3   feature4   feature5  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.356115   0.659151   0.534851   1.456609   0.620374   0.246584   \n",
       "std     0.528450   0.717040   0.634626   1.469262   0.863010   0.516834   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.000000   0.040266   0.000000   0.132334   0.000000   0.000000   \n",
       "50%     0.127216   0.490579   0.207641   1.129262   0.065244   0.003843   \n",
       "75%     0.588773   0.997432   0.863077   2.156846   1.134359   0.231311   \n",
       "max     2.387135   2.503587   2.039248   5.101050   3.332864   2.486209   \n",
       "\n",
       "        feature6   feature7   feature8   feature9     ...       feature1014  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000     ...         50.000000   \n",
       "mean    0.492389   0.561619   0.351571   0.326255     ...          0.348105   \n",
       "std     0.615499   0.786240   0.504510   0.529641     ...          0.596924   \n",
       "min     0.000000   0.000000   0.000000   0.000000     ...          0.000000   \n",
       "25%     0.000000   0.028203   0.001209   0.000000     ...          0.000000   \n",
       "50%     0.160384   0.235029   0.126061   0.087056     ...          0.031689   \n",
       "75%     0.774815   0.796812   0.432390   0.494191     ...          0.457193   \n",
       "max     2.051370   3.632538   1.927134   2.294356     ...          2.975513   \n",
       "\n",
       "       feature1015  feature1016  feature1017  feature1018  feature1019  \\\n",
       "count    50.000000    50.000000    50.000000    50.000000    50.000000   \n",
       "mean      0.516225     0.331030     0.426340     0.901045     0.854171   \n",
       "std       0.714570     0.593420     0.541888     1.082123     0.938720   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.041860     0.142003     0.049615   \n",
       "50%       0.147620     0.000150     0.295788     0.338905     0.495983   \n",
       "75%       0.890692     0.446506     0.636890     1.380113     1.505200   \n",
       "max       3.255536     2.505214     2.708307     4.099638     2.904099   \n",
       "\n",
       "       feature1020  feature1021  feature1022  feature1023  \n",
       "count    50.000000    50.000000    50.000000    50.000000  \n",
       "mean      2.114770     0.898444     0.832099     0.524872  \n",
       "std       2.271520     0.881170     1.180123     0.543327  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.287843     0.034842     0.000000     0.032638  \n",
       "50%       0.958504     0.722759     0.229320     0.397400  \n",
       "75%       5.172260     1.607077     1.638849     0.772724  \n",
       "max       5.694676     3.223482     4.226102     1.864173  \n",
       "\n",
       "[8 rows x 1024 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this fan diagram, we can see that there are the same number of the true and the fake samples in the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1, 1.1, -1.1, 1.1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "data_solution = pd.read_csv(\"sample_data/perso_train.solution\",header=None) \n",
    "data_solution.rename(columns={ data_solution.columns[0]: \"solution\" }, inplace=True)\n",
    "counts = data_solution['solution'].value_counts()\n",
    "values = data_solution['solution'].unique()\n",
    "colors = ['turquoise', 'seagreen']\n",
    "plt.pie(counts, labels=values, colors=colors)\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram is a representation of the distribution of data. This function calls matplotlib.pyplot.hist(), on each series in the DataFrame, resulting in one histogram per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"feature0\"].hist(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<h1>Step 2: Building a predictive model</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Loading data with DataManager</h2>\n",
    "    <p>\n",
    "We reload the data with the AutoML DataManager class because this is more convenient:\n",
    "   <br>     <span style=\"color:red\"> Keep this, it illustrates how data in AutoML formal are loaded by the ingestion program </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_public.info\n",
      "DataManager : perso\n",
      "info:\n",
      "\tusage = Sample dataset perso data\n",
      "\tname = perso\n",
      "\ttask = bi-class.classification\n",
      "\ttarget_type = Numerical\n",
      "\tfeat_type = Numerical\n",
      "\tmetric = bac_metric\n",
      "\ttime_budget = 1200\n",
      "\tfeat_num = 1024\n",
      "\ttarget_num = 2\n",
      "\tlabel_num = 2\n",
      "\ttrain_num = 50\n",
      "\tvalid_num = 50\n",
      "\ttest_num = 50\n",
      "\thas_categorical = 0\n",
      "\thas_missing = 0\n",
      "\tis_sparse = 0\n",
      "\tformat = dense\n",
      "data:\n",
      "\tX_train = array(50, 1024)\n",
      "\tY_train = array(50,)\n",
      "\tX_valid = array(50, 1024)\n",
      "\tY_valid = array(50,)\n",
      "\tX_test = array(50, 1024)\n",
      "\tY_test = array(50,)\n",
      "feat_type:\tarray(1024,)\n",
      "feat_idx:\tarray(0,)\n",
      "\n",
      "perso\n"
     ]
    }
   ],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager(data_name, data_dir, replace_missing=True)\n",
    "print(D)\n",
    "print(data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Training a predictive model</h2>\n",
    "    <p>\n",
    "We provide an example of predictive model (for classification or regression) in the `sample_code_submission/` directory. It is a quite stupid model: it makes constant predictions. Replace it with your own model.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/min/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from numpy.core.umath_tests import inner1d\n",
    "from data_io import write\n",
    "from model import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "an instance of the model (run the constructor) and attempt to reload a previously saved version from `sample_code_submission/`:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perso\n",
      "sample_code_submission/\n",
      "sample_code_submission/perso\n"
     ]
    }
   ],
   "source": [
    "M = model()\n",
    "trained_model_name = model_dir + data_name\n",
    "print(data_name)\n",
    "print(model_dir)\n",
    "print(trained_model_name)\n",
    "# Uncomment the next line to re-load an already trained model\n",
    "#M = M.load(trained_model_name)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Train the model (unless you reloaded a trained model) and make predictions. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT: dim(X)= [50, 1024]\n",
      "FIT: dim(y)= [50, 1]\n",
      "PREDICT: dim(X)= [50, 1024]\n",
      "PREDICT: dim(y)= [50, 1]\n",
      "PREDICT: dim(X)= [50, 1024]\n",
      "PREDICT: dim(y)= [50, 1]\n",
      "PREDICT: dim(X)= [50, 1024]\n",
      "PREDICT: dim(y)= [50, 1]\n"
     ]
    }
   ],
   "source": [
    "if not(M.is_trained):\n",
    "    X_train = D.data['X_train']\n",
    "    Y_train = D.data['Y_train']\n",
    "    M.fit(X_train, Y_train)                     \n",
    "\n",
    "Y_hat_train = M.predict(D.data['X_train'])\n",
    "Y_hat_valid = M.predict(D.data['X_valid'])\n",
    "Y_hat_test = M.predict(D.data['X_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <b> Save the trained model </b> (will be ready to reload next time around) and save the prediction results. IMPORTANT: if you save the trained model, it will be bundled with your sample code submission. Therefore your model will NOT be retrained on the challenge platform. Remove the pickle from the submission if you want the model to be retrained on the platform.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_result_submission/perso_test.predict\r\n",
      "sample_result_submission/perso_train.predict\r\n",
      "sample_result_submission/perso_valid.predict\r\n"
     ]
    }
   ],
   "source": [
    "M.save(trained_model_name)                 \n",
    "result_name = result_dir + data_name\n",
    "from data_io import write\n",
    "write(result_name + '_train.predict', Y_hat_train)\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "write(result_name + '_test.predict', Y_hat_test)\n",
    "!ls $result_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Scoring the results</h2>\n",
    "    <h3>Load the challenge metric</h3>\n",
    "    <p>\n",
    "<b>The metric chosen for your challenge</b> is identified in the \"metric.txt\" file found in the `scoring_function/` directory. The function \"get_metric\" searches first for a metric having that name in my_metric.py, then in libscores.py, then in sklearn.metric.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'auc_binary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/s5/PersoData/starting_kit/scoring_program/libscores.py\u001b[0m in \u001b[0;36mget_metric\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mscoring_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'my_metric' has no attribute 'auc_binary'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/s5/PersoData/starting_kit/scoring_program/libscores.py\u001b[0m in \u001b[0;36mget_metric\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mscoring_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'libscores' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-410aff282dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlibscores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using scoring metric:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Uncomment the next line to display the code of the scoring metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#??scoring_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/s5/PersoData/starting_kit/scoring_program/libscores.py\u001b[0m in \u001b[0;36mget_metric\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mscoring_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mscoring_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'auc_binary'"
     ]
    }
   ],
   "source": [
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)\n",
    "# Uncomment the next line to display the code of the scoring metric\n",
    "#??scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h3> Training performance </h3>\n",
    "    <p>\n",
    "The participants normally posess target values (labels) only for training examples (except for the sample data). We compute with the `example` metric the training score, which should be zero for perfect predictions.\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for the accuracy_score metric = 1.0000\n",
      "Ideal score for the accuracy_score metric = 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train))\n",
    "print('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add here other scores and result visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  0],\n",
       "       [ 0, 25]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_train, Y_hat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h3>Cross-validation performance</h3>\n",
    "    <p>\n",
    "The participants do not have access to the labels Y_valid and Y_test to self-assess their validation and test performances. But training performance is not a good prediction of validation or test performance. Using cross-validation, the training data is split into multiple training/test folds, which allows participants to self-assess their model during development. The average CV result and 95% confidence interval is displayed.\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT: dim(X)= [40, 1024]\n",
      "FIT: dim(y)= [40, 1]\n",
      "PREDICT: dim(X)= [10, 1024]\n",
      "PREDICT: dim(y)= [10, 1]\n",
      "FIT: dim(X)= [40, 1024]\n",
      "FIT: dim(y)= [40, 1]\n",
      "PREDICT: dim(X)= [10, 1024]\n",
      "PREDICT: dim(y)= [10, 1]\n",
      "FIT: dim(X)= [40, 1024]\n",
      "FIT: dim(y)= [40, 1]\n",
      "PREDICT: dim(X)= [10, 1024]\n",
      "PREDICT: dim(y)= [10, 1]\n",
      "FIT: dim(X)= [40, 1024]\n",
      "FIT: dim(y)= [40, 1]\n",
      "PREDICT: dim(X)= [10, 1024]\n",
      "PREDICT: dim(y)= [10, 1]\n",
      "FIT: dim(X)= [40, 1024]\n",
      "FIT: dim(y)= [40, 1]\n",
      "PREDICT: dim(X)= [10, 1024]\n",
      "PREDICT: dim(y)= [10, 1]\n",
      "\n",
      "CV score (95 perc. CI): 0.70 (+/- 0.47)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(M, X_train, Y_train, cv=5, scoring=make_scorer(scoring_function))\n",
    "print('\\nCV score (95 perc. CI): %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<h1> Step 3: Making a submission </h1> \n",
    "\n",
    "<h2> Unit testing </h2> \n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission. \n",
    "<br>\n",
    "Keep the sample code simple.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input_dir: /home/min/workspace/s5/PersoData/starting_kit/sample_data\n",
      "Using output_dir: /home/min/workspace/s5/PersoData/starting_kit/sample_result_submission\n",
      "Using program_dir: /home/min/workspace/s5/PersoData/starting_kit/ingestion_program\n",
      "Using submission_dir: /home/min/workspace/s5/PersoData/starting_kit/sample_code_submission\n",
      "/home/min/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "\n",
      "========== Ingestion program version 6 ==========\n",
      "\n",
      "************************************************\n",
      "******** Processing dataset Perso ********\n",
      "************************************************\n",
      "========= Reading and converting data ==========\n",
      "Info file found : /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_public.info\n",
      "========= Reading /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_train.data\n",
      "Replace missing values by 0 (slow, sorry)\n",
      "[+] Success in  0.01 sec\n",
      "========= Reading /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_train.solution\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_valid.data\n",
      "Replace missing values by 0 (slow, sorry)\n",
      "[+] Success in  0.01 sec\n",
      "========= Reading /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_valid.solution\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_test.data\n",
      "Replace missing values by 0 (slow, sorry)\n",
      "[+] Success in  0.01 sec\n",
      "========= Reading /home/min/workspace/s5/PersoData/starting_kit/sample_data/perso_test.solution\n",
      "[+] Success in  0.00 sec\n",
      "DataManager : perso\n",
      "info:\n",
      "\tusage = Sample dataset perso data\n",
      "\tname = perso\n",
      "\ttask = bi-class.classification\n",
      "\ttarget_type = Numerical\n",
      "\tfeat_type = Numerical\n",
      "\tmetric = bac_metric\n",
      "\ttime_budget = 1200\n",
      "\tfeat_num = 1024\n",
      "\ttarget_num = 2\n",
      "\tlabel_num = 2\n",
      "\ttrain_num = 50\n",
      "\tvalid_num = 50\n",
      "\ttest_num = 50\n",
      "\thas_categorical = 0\n",
      "\thas_missing = 0\n",
      "\tis_sparse = 0\n",
      "\tformat = dense\n",
      "data:\n",
      "\tX_train = array(50, 1024)\n",
      "\tY_train = array(50,)\n",
      "\tX_valid = array(50, 1024)\n",
      "\tY_valid = array(50,)\n",
      "\tX_test = array(50, 1024)\n",
      "\tY_test = array(50,)\n",
      "feat_type:\tarray(1024,)\n",
      "feat_idx:\tarray(1024,)\n",
      "\n",
      "[+] Size of uploaded data  56.00 bytes\n",
      "[+] Cumulated time budget (all tasks so far)  1200.00 sec\n",
      "[+] Time budget for this task 1200.00 sec\n",
      "[+] Remaining time after reading data 1199.96 sec\n",
      "======== Creating model ==========\n",
      "**********************************************************\n",
      "****** Attempting to reload model to avoid training ******\n",
      "**********************************************************\n",
      "Model reloaded from: /home/min/workspace/s5/PersoData/starting_kit/sample_code_submission/perso_model.pickle\n",
      "[+] Model reloaded, no need to train!\n",
      "[+] Prediction success, time spent so far  0.04 sec\n",
      "======== Saving results to: /home/min/workspace/s5/PersoData/starting_kit/sample_result_submission\n",
      "[+] Results saved, time spent so far  0.04 sec\n",
      "[+] End cycle, time left 1199.96 sec\n",
      "[+] Done\n",
      "[+] Overall time spent  0.79 sec ::  Overall time budget 1200.00 sec\n"
     ]
    }
   ],
   "source": [
    "!python $problem_dir/ingestion.py $data_dir $result_dir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "Also test the scoring program:\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Set 1 (Perso_test): accuracy_score(set1_score)=0.920000000000 =======\r\n",
      "======= Set 2 (Perso_train): accuracy_score(set2_score)=1.000000000000 =======\r\n",
      "======= Set 3 (Perso_valid): accuracy_score(set3_score)=0.900000000000 =======\r\n"
     ]
    }
   ],
   "source": [
    "scoring_output_dir = '../scoring_output_dir'\n",
    "!python $score_dir/score.py $data_dir $result_dir $scoring_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h1> Preparing the submission </h1>\n",
    "\n",
    "Zip the contents of `sample_code_submission/` (without the directory), or download the challenge public_data and run the command in the previous cell, after replacing sample_data by public_data.\n",
    "Then zip the contents of `sample_result_submission/` (without the directory).\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit one of these files:\n",
      "../sample_code_submission_18-11-21-19-52.zip\n",
      "../sample_result_submission_18-11-21-19-52.zip\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = '../sample_code_submission_' + the_date + '.zip'\n",
    "sample_result_submission = '../sample_result_submission_' + the_date + '.zip'\n",
    "zipdir(sample_code_submission, model_dir)\n",
    "zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\" + sample_result_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
